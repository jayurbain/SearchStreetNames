{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Location Data Extraction\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "datafile = '../data/fl.csv'\n",
    "\n",
    "df = pd.read_csv(datafile)\n",
    "df.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_florida = df[ df['Lossstate']=='florida' ]\n",
    "df_florida.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_florida.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_florida.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_florida.to_csv('florida_locations_raw.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_florida['Lossstreet'] = df_florida['Lossstreet'].replace(r'\\brd\\b','road', regex=True) \\\n",
    "                                                    .replace(r'\\bst\\b','street', regex=True) \\\n",
    "                                                    .replace(r'\\bave\\b','avenue', regex=True).copy()\n",
    "df_florida.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_florida['loss_details'] = df_florida['loss_details'].replace(r'\\brd\\b','road', regex=True) \\\n",
    "                                                    .replace(r'\\bst\\b','street', regex=True) \\\n",
    "                                                    .replace(r'\\bave\\b','avenue', regex=True).copy()\n",
    "df_florida.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Replace rd, st, and ave wiith road, street, and avenue respectively"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# loss location level2\n",
    "\n",
    "df_florida['loss location level2'] = df_florida['loss location level2'].replace(r'\\brd\\b','road', regex=True) \\\n",
    "                                                    .replace(r'\\bst\\b','street', regex=True) \\\n",
    "                                                    .replace(r'\\bave\\b','avenue', regex=True).copy()\n",
    "df_florida.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Substitute numbers with words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def num2words(num):\n",
    "    under_20 = ['Zero','One','Two','Three','Four','Five','Six','Seven','Eight','Nine','Ten','Eleven','Twelve','Thirteen','Fourteen','Fifteen','Sixteen','Seventeen','Eighteen','Nineteen']\n",
    "    tens = ['Twenty','Thirty','Forty','Fifty','Sixty','Seventy','Eighty','Ninety']\n",
    "    above_100 = {100: 'Hundred',1000:'Thousand', 1000000:'Million', 1000000000:'Billion'}\n",
    " \n",
    "    if num < 20:\n",
    "        return under_20[num]\n",
    "\n",
    "    if num < 100:\n",
    "        return tens[(int)(num/10)-2] + ('' if num%10==0 else ' ' + under_20[num%10])\n",
    " \n",
    "    # find the appropriate pivot - 'Million' in 3,603,550, or 'Thousand' in 603,550\n",
    "    pivot = max([key for key in above_100.keys() if key <= num])\n",
    " \n",
    "    return num2words((int)(num/pivot)) + ' ' + above_100[pivot] + ('' if num%pivot==0 else ' ' + num2words(num%pivot))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def num2words_x2(num):\n",
    "    under_20 = ['Zero','One','Two','Three','Four','Five','Six','Seven','Eight','Nine','Ten','Eleven','Twelve','Thirteen','Fourteen','Fifteen','Sixteen','Seventeen','Eighteen','Nineteen']\n",
    "    \n",
    "    num_s = \"\"\n",
    "    for i in str(num):\n",
    "        num_s = num_s + ' ' + under_20[ int(i)]\n",
    "\n",
    "    print(num_s.strip())\n",
    "    return num_s.strip()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = \"state road 429\"\n",
    "def number_replace(match):\n",
    "    num = match.group()\n",
    "    return num2words(int(num)).lower()\n",
    "\n",
    "re.sub(r'([0-9]+)', number_replace, s)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lossstreet_n2w = []\n",
    "for index, row in df_florida.iterrows():\n",
    "    Lossstreet = row['Lossstreet']\n",
    "    Lossstreet_w = re.sub(r'([0-9]+)', number_replace, Lossstreet)\n",
    "    print( Lossstreet, Lossstreet_w)\n",
    "    lossstreet_n2w.append(Lossstreet_w)\n",
    "    \n",
    "#     count += 1\n",
    "#     if count == 10:\n",
    "#        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_florida['lossstreet_n2w']=lossstreet_n2w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_florida.to_csv('../data/florida_locations.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/florida_locations.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['loss location level2'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['loss_details'][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "import requests\n",
    "import json\n",
    "\n",
    "def get_entity_annotation(d):\n",
    "    r = requests.post('https://cis.ctsi.mcw.edu/nlp/nlpservice', data = d)\n",
    "    r2 = r.text + ']}'\n",
    "    d = json.loads(r2)\n",
    "\n",
    "    annotation_list = []\n",
    "    tcount=1\n",
    "    nlplist = d['nlplist']\n",
    "    entity_dict = {}\n",
    "    for entitylists in nlplist:\n",
    "        entitylist = entitylists['entitylist']\n",
    "        for entitydict in entitylist:\n",
    "            e = entitydict['cui']+'_'+entitydict['preferredText']\n",
    "            e = e.replace(\",\",\"\").replace(\"(\",\"\").replace(\")\",\"\").replace(\"/\", \"_\").replace(\" \", \"_\").replace(\"'\", \"_\").replace(\":\", \"_\").replace(\"+\", \"\")\n",
    "            s = 'T'+str(tcount)+'\\t'+e+' '+entitydict['begin']+' '+entitydict['end']+'\\t'+entitydict['coveredText']\n",
    "#             s = s.replace(\",\",\"\").replace(\"(\",\"\").replace(\")\",\"\").replace(\" \", \"_\")\n",
    "            annotation_list.append(s)\n",
    "            tcount += 1\n",
    "            entity_dict[e]=entitydict['preferredText']\n",
    "    return annotation_list, entity_dict\n",
    "\n",
    "d = '{\"recordlist\":[\"Jay is elderly\",\"Treated for illusions of grandeur\",\"Family history of CAD\"]}'\n",
    "annotation_list = get_entity_annotation(d)\n",
    "for a in annotation_list:\n",
    "    print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "count = 0\n",
    "\n",
    "print(df.columns)\n",
    "#annotations = []\n",
    "dir_out = './street_annotations/'\n",
    "\n",
    "for index, row in df.iterrows():\n",
    "    RecordingID = row['RecordingID']\n",
    "    Losscity = row['Losscity']\n",
    "    Lossstate = row['Lossstate']\n",
    "    Mapaddress = row['Mapaddress']\n",
    "    Lossstreet = row['Lossstreet']\n",
    "    loss_details = row['loss_details']\n",
    "    loss_location_level2 = row['loss location level2']\n",
    "    lossstreet_n2w = row['lossstreet_n2w']\n",
    "#     print(lossstreet_n2w, [Lossstreet, loss_location_level2])\n",
    "    annotation_string = \"\"\n",
    "    tcount=1\n",
    "    end = -1\n",
    "    lossstreet_n2w = Lossstreet\n",
    "    start = loss_location_level2.find(lossstreet_n2w)\n",
    "    print('---')\n",
    "    print( loss_location_level2 )\n",
    "    if start == -1:\n",
    "        print( lossstreet_n2w )\n",
    "        lossstreet_n2w = re.sub(r'([0-9]+)', '', lossstreet_n2w).strip()\n",
    "        print( lossstreet_n2w )\n",
    "        start = loss_location_level2.find(lossstreet_n2w)\n",
    "    if start > -1:\n",
    "        end = start + len(lossstreet_n2w)\n",
    "        annotation_string = 'T'+str(tcount)+'\\t'+'STREET'+' '+str(start)+' '+str(end)+'\\t'+lossstreet_n2w\n",
    "        tcount += 1\n",
    "        print(annotation_string, ',', Lossstreet)\n",
    "        #annotations.append((RecordingID, s, loss_location_level2))\n",
    "    else:\n",
    "        print('nada')\n",
    "        \n",
    "    fnametxt = str(RecordingID)+'.txt'\n",
    "    fnameann = str(RecordingID)+'.ann'\n",
    "    f = dir_out+fnametxt\n",
    "    ftxt = open(f,\"w+\",encoding='utf-8')\n",
    "    print(loss_location_level2, file=ftxt)\n",
    "    ftxt.close()\n",
    "    f = dir_out+fnameann\n",
    "    fann = open(f,\"w+\",encoding='utf-8')\n",
    "    print(annotation_string, file=fann)\n",
    "    fann.close()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = '1771 ponkan road'\n",
    "x = re.sub(r'([0-9]+)', '', s).strip()\n",
    "s.find(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!mkdir street_annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
